{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c61cb85",
   "metadata": {},
   "source": [
    "\n",
    "# `skrub` - where to we head to?\n",
    "\n",
    "## A new way to assemble data\n",
    "\n",
    "WIP: https://github.com/skrub-data/skrub/pull/1233\n",
    "\n",
    "If you have a database with several tables, then you will need to assemble them.\n",
    "\n",
    "We will see that using tools as `pandas` or `polars` when dealing with machine\n",
    "learning processes is far to be easy.\n",
    "\n",
    "Let's look at such a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e75b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub\n",
    "from skrub.datasets import fetch_credit_fraud\n",
    "\n",
    "dataset = fetch_credit_fraud()\n",
    "skrub.TableReport(dataset.baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d51b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skrub.TableReport(dataset.products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of basket looks like this\n",
    "next(iter(dataset.products.groupby(\"basket_ID\")))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989ca63",
   "metadata": {},
   "source": [
    "So let's develop a predictive model to predict whether a basket is fraudulent or not.\n",
    "\n",
    "We can use the `TableVectorizer` to vectorize the strings in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e976f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = skrub.TableVectorizer(high_cardinality=skrub.StringEncoder(), n_jobs=-1)\n",
    "vectorized_products = vectorizer.fit_transform(dataset.products)\n",
    "vectorized_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99ad70",
   "metadata": {},
   "source": [
    "\n",
    "We can now aggregate the products and join the tables: pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e636f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_products = vectorized_products.groupby(\"basket_ID\").agg(\"mean\").reset_index()\n",
    "aggregated_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = dataset.baskets.merge(\n",
    "    aggregated_products, left_on=\"ID\", right_on=\"basket_ID\"\n",
    ").drop(columns=[\"ID\", \"basket_ID\"])\n",
    "baskets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb600ea",
   "metadata": {},
   "source": [
    "\n",
    "Great I have a dataset on which I can train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9549984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "y = baskets[\"fraud_flag\"]\n",
    "X = baskets.drop(\"fraud_flag\", axis=1)\n",
    "\n",
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "cv_results = cross_validate(model, X, y, scoring=\"roc_auc\", return_train_score=True)\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[[\"train_score\", \"test_score\"]].aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35efd0a",
   "metadata": {},
   "source": [
    "\n",
    "But things are ready to go sideways:\n",
    "We're in pandas' land. When comes new data, how to apply the same transformations?\n",
    "How to cross-validate, or tune the data-preparation steps?\n",
    "\n",
    "`scikit-learn` fanatics would say: \"use pipelines\".\n",
    "\n",
    "But the current `scikit-learn` pipelines do not easily go back up to the data source.\n",
    "\n",
    "So let's see what `skrub` envisions for this.\n",
    "\n",
    "We define our inputs as \"variables\": you can see them as the \"source\" of the data.\n",
    "They are symbolic, meaning that they will allow to record the transformations applied\n",
    "to the data. Additionally, we are able to pass a concrete datasets to them such that\n",
    "we have an eager evaluation of the transformations to see if what we do works as\n",
    "expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = skrub.var(\"products\", dataset.products)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a9b02",
   "metadata": {},
   "source": [
    "\n",
    "Now we define our \"X\" and \"y\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = skrub.var(\"baskets\", dataset.baskets)\n",
    "basket_IDs = baskets[[\"ID\"]].skb.mark_as_X()\n",
    "fraud_flags = baskets[\"fraud_flag\"].skb.mark_as_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea879ca",
   "metadata": {},
   "source": [
    "\n",
    "`skrub` provides a `polars`-like API to select columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import selectors as s\n",
    "\n",
    "vectorized_products = products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "vectorized_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40542ff4",
   "metadata": {},
   "source": [
    "\n",
    "We aggregate the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_products = vectorized_products.groupby(\"basket_ID\").agg(\"mean\").reset_index()\n",
    "aggregated_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434c134",
   "metadata": {},
   "source": [
    "\n",
    "And we join the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81384708",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = basket_IDs.merge(aggregated_products, left_on=\"ID\", right_on=\"basket_ID\")\n",
    "features = features.drop(columns=[\"ID\", \"basket_ID\"])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ade344",
   "metadata": {},
   "source": [
    "\n",
    "And we do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5310d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "predictions = features.skb.apply(ExtraTreesClassifier(n_jobs=-1), y=fraud_flags)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda95d6b",
   "metadata": {},
   "source": [
    "What's the big deal? We now have a graph of computations\n",
    "We can apply it to new data\n",
    "\n",
    "We load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = fetch_credit_fraud(split=\"test\")\n",
    "y_test = data_test.baskets[\"fraud_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_test = data_test.baskets.drop(\"fraud_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2584a",
   "metadata": {},
   "source": [
    "\n",
    "We can apply a predictor to this new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a126078",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(predictions.skb.get_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = predictions.skb.get_estimator(fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = predictor.predict(\n",
    "    {\n",
    "        \"baskets\": basket_test,\n",
    "        \"products\": data_test.products,\n",
    "    }\n",
    ")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94215003",
   "metadata": {},
   "source": [
    "\n",
    "We can also tune hyperparameters of our data preparation. We just need to\n",
    "change a bit the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c834d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = skrub.StringEncoder(\n",
    "    vectorizer=skrub.choose_from([\"tfidf\", \"hashing\"], name=\"vectorizer\"),\n",
    ")\n",
    "vectorizer = skrub.TableVectorizer(high_cardinality=encoder, n_jobs=2)\n",
    "extra_trees = ExtraTreesClassifier(\n",
    "    max_leaf_nodes=skrub.choose_from([10, 30, 100], name=\"max_leaf_nodes\"),\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af57fa",
   "metadata": {},
   "source": [
    "\n",
    "The rest of the code remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d244bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_products = products.skb.apply(vectorizer, cols=s.all() - \"basket_ID\")\n",
    "aggregated_products = vectorized_products.groupby(\"basket_ID\").agg(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2a6e0",
   "metadata": {},
   "source": [
    "\n",
    "We redefine our sources, to have a clean start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "predictions_path = Path(\"../data/02_predictions.joblib\")\n",
    "search_path = Path(\"../data/02_search.joblib\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = joblib.load(predictions_path)\n",
    "    search = joblib.load(search_path)\n",
    "else:\n",
    "    baskets = skrub.var(\"baskets\", dataset.baskets)\n",
    "    basket_IDs = baskets[[\"ID\"]].skb.mark_as_X()\n",
    "    fraud_flags = baskets[\"fraud_flag\"].skb.mark_as_y()\n",
    "    features = basket_IDs.merge(aggregated_products, left_on=\"ID\", right_on=\"basket_ID\")\n",
    "    features = features.drop(columns=[\"ID\", \"basket_ID\"])\n",
    "    predictions = features.skb.apply(extra_trees, y=fraud_flags)\n",
    "    search = predictions.skb.get_grid_search(fitted=True, scoring=\"roc_auc\", verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e333fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32923522",
   "metadata": {},
   "source": [
    "\n",
    "`skrub` gives you all kinds of tools to tune and inspect this pipeline:\n",
    "For instance, we can visualize the hyperparameters selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879dd4a",
   "metadata": {},
   "source": [
    "\n",
    "We can also get a full report of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0118b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.skb.full_report()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
