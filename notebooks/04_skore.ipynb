{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec08799",
   "metadata": {},
   "source": [
    "\n",
    "# `Skore` - an abstraction to ease data science project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855ef8c",
   "metadata": {},
   "source": [
    "\n",
    "Let's open a skore project in which we will be able to store artifacts from our\n",
    "experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skore\n",
    "\n",
    "my_project = skore.Project(\"../data/my_project\", if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e99206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "datasets = fetch_employee_salaries()\n",
    "df, y = datasets.X, datasets.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableReport\n",
    "\n",
    "table_report = TableReport(datasets.employee_salaries)\n",
    "table_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48a085",
   "metadata": {},
   "source": [
    "\n",
    "Let's model our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer, TextEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(\n",
    "    TableVectorizer(high_cardinality=TextEncoder()),\n",
    "    RandomForestRegressor(n_estimators=20, max_leaf_nodes=40),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119d8e2",
   "metadata": {},
   "source": [
    "\n",
    "`skore` provides a couple of tools to ease the evaluation of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skore import CrossValidationReport\n",
    "\n",
    "report = CrossValidationReport(estimator=model, X=df, y=y, cv_splitter=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93792a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "score = report.metrics.r2()\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86940b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46445aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "score = report.metrics.r2()\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c06707",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c90193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "score = report.metrics.rmse()\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042df7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.cache_predictions(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb521193",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project.put(\"Random Forest model report\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = my_project.get(\"Random Forest model report\")\n",
    "report.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.metrics.report_metrics(aggregate=[\"mean\", \"std\"], indicator_favorability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = report.metrics.prediction_error()\n",
    "display.plot(kind=\"actual_vs_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.estimator_reports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_report = report.estimator_reports_[0]\n",
    "estimator_report.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_report.metrics.prediction_error().plot(kind=\"actual_vs_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a016bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skrub\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "model = skrub.tabular_learner(RidgeCV(np.logspace(-3, 3, 10)))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = CrossValidationReport(estimator=model, X=df, y=y, cv_splitter=5, n_jobs=-1)\n",
    "my_project.put(\"RidgeCV model report\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ebfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skore import ComparisonReport\n",
    "\n",
    "report = ComparisonReport(\n",
    "    reports={\n",
    "        \"Random Forest\": my_project.get(\"Random Forest model report\"),\n",
    "        \"RidgeCV\": my_project.get(\"RidgeCV model report\"),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.metrics.report_metrics(indicator_favorability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56af167",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions\n",
    "\n",
    "**Vision**\n",
    "- Develop tooling to create data science artifacts\n",
    "- Help at following good practices for the problem at hand\n",
    "- Help at the collaboration to carry on data science project\n",
    "\n",
    "**Wrap-up**\n",
    "- Provide tools to evaluate predictive models\n",
    "- Make some internal magic to reduce user friction\n",
    "- Allow for persistence of artifacts\n",
    "\n",
    "**Roadmap**\n",
    "- Cover multiple aspects of the data science life cycles: data, model, etc.\n",
    "- Help at creating artifacts dedicated to the problem at hand and the model\n",
    "- Reduce the complexity related to code"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
